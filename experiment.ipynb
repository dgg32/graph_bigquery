{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yaml\n",
    "import json\n",
    "import os\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        PARAM = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = GraphDatabase.driver(PARAM[\"neo4j_url\"], auth=(PARAM[\"neo4j_username\"], PARAM[\"neo4j_password\"]))\n",
    "\n",
    "records, summary, keys = driver.execute_query(f\"\"\"\n",
    "    CALL apoc.meta.schema()\n",
    "    YIELD value RETURN value;\n",
    "    \"\"\",\n",
    "    database_=\"neo4j\",\n",
    ")\n",
    "# Loop through results and do something with them\n",
    "for record in records:\n",
    "    schema = record.data()[\"value\"]\n",
    "    json_schema = json.dumps(record.data()[\"value\"])\n",
    "    #print (json_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Condition', 'IS_A_SITE_OF', 'Site', 'IS_A_CATEGORY_OF', 'IS_CARRIED_OUT_BY', 'FOCUSES_ON', 'IS_FOUND_AT_SITE', 'Institution', 'BELONGS_TO', 'HAS_MORPHOLOGY', 'Category', 'Trial', 'Morphology'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'node'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema['Condition']['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 23,\n",
       " 'labels': [],\n",
       " 'properties': {'SNOMEDCT': {'unique': True,\n",
       "   'indexed': True,\n",
       "   'type': 'STRING',\n",
       "   'existence': False},\n",
       "  'name': {'unique': False,\n",
       "   'indexed': False,\n",
       "   'type': 'STRING',\n",
       "   'existence': False},\n",
       "  'UMLS': {'unique': False,\n",
       "   'indexed': False,\n",
       "   'type': 'STRING',\n",
       "   'existence': False}},\n",
       " 'type': 'node',\n",
       " 'relationships': {'HAS_MORPHOLOGY': {'count': 0,\n",
       "   'direction': 'out',\n",
       "   'labels': ['Morphology'],\n",
       "   'properties': {}},\n",
       "  'FOCUSES_ON': {'count': 26,\n",
       "   'direction': 'in',\n",
       "   'labels': ['Trial'],\n",
       "   'properties': {}},\n",
       "  'IS_FOUND_AT_SITE': {'count': 0,\n",
       "   'direction': 'out',\n",
       "   'labels': ['Site'],\n",
       "   'properties': {}},\n",
       "  'BELONGS_TO': {'count': 0,\n",
       "   'direction': 'out',\n",
       "   'labels': ['Category'],\n",
       "   'properties': {}}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema['Condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Condition: {SNOMEDCT: STRING}\n",
    "schema_dict = {}\n",
    "for key in schema.keys():\n",
    "    if schema[key]['type'] == 'node':\n",
    "        schema_dict[key] = {}\n",
    "\n",
    "        for p in schema[key]['properties'].keys():\n",
    "            schema_dict[key][p] = schema[key]['properties'][p]['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Condition': {'SNOMEDCT': 'STRING', 'name': 'STRING', 'UMLS': 'STRING'},\n",
       " 'Site': {'fsn': 'STRING', 'SNOMEDCT': 'STRING', 'name': 'STRING'},\n",
       " 'Institution': {'name': 'STRING', 'type': 'STRING'},\n",
       " 'Category': {'fsn': 'STRING', 'SNOMEDCT': 'STRING', 'name': 'STRING'},\n",
       " 'Trial': {'min_age': 'STRING',\n",
       "  'healthy_volunteers': 'STRING',\n",
       "  'study_results': 'STRING',\n",
       "  'outcome_measures': 'LIST',\n",
       "  'criteria': 'STRING',\n",
       "  'status': 'STRING',\n",
       "  'max_age': 'STRING',\n",
       "  'study_type': 'STRING',\n",
       "  'url': 'STRING',\n",
       "  'title': 'STRING',\n",
       "  'locations': 'LIST',\n",
       "  'description': 'STRING',\n",
       "  'name': 'STRING',\n",
       "  'phases': 'LIST',\n",
       "  'gender': 'STRING',\n",
       "  'enrollment': 'STRING',\n",
       "  'start_date': 'STRING',\n",
       "  'sampling_method': 'STRING'},\n",
       " 'Morphology': {'fsn': 'STRING', 'SNOMEDCT': 'STRING', 'name': 'STRING'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SNOMEDCT': {'unique': True,\n",
       "  'indexed': True,\n",
       "  'type': 'STRING',\n",
       "  'existence': False},\n",
       " 'name': {'unique': False,\n",
       "  'indexed': False,\n",
       "  'type': 'STRING',\n",
       "  'existence': False},\n",
       " 'UMLS': {'unique': False,\n",
       "  'indexed': False,\n",
       "  'type': 'STRING',\n",
       "  'existence': False}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema['Condition']['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition\n",
      "Site\n",
      "Institution\n",
      "Category\n",
      "Trial\n",
      "Morphology\n"
     ]
    }
   ],
   "source": [
    "for label in schema.keys():\n",
    "    if schema[label]['type'] == 'node':\n",
    "        print (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable_name = \"t\"\n",
    "# output_directory = \"tsv\"\n",
    "\n",
    "# for node_type in schema.keys():\n",
    "#     if schema[node_type]['type'] == 'node':\n",
    "\n",
    "#         records, summary, keys = driver.execute_query(f\"\"\"\n",
    "#             MATCH ({variable_name}:{node_type})\n",
    "#             RETURN {variable_name}\n",
    "#             \"\"\",\n",
    "#             database_=\"neo4j\",\n",
    "#         )\n",
    "        \n",
    "#         header = list(schema[node_type]['properties'].keys())\n",
    "#         content = \"\\t\".join(header) + \"\\n\"\n",
    "#         for record in records:\n",
    "#             result = record.data()[f\"{variable_name}\"]\n",
    "            \n",
    "#             for h in header:\n",
    "#                 if h in result:\n",
    "#                     content += str(result[h]) + \"\\t\"\n",
    "#                 else:\n",
    "#                     content += \"\\t\"\n",
    "#             content = content[:-1] + \"\\n\"\n",
    "\n",
    "#         with open(os.path.join(output_directory, f\"{node_type}.tsv\"), 'w') as f:\n",
    "#             f.write(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_name = \"t\"\n",
    "output_directory = \"json\"\n",
    "\n",
    "for node_type in schema.keys():\n",
    "    if schema[node_type]['type'] == 'node':\n",
    "\n",
    "        records, summary, keys = driver.execute_query(f\"\"\"\n",
    "            MATCH ({variable_name}:{node_type})\n",
    "            RETURN {variable_name}\n",
    "            \"\"\",\n",
    "            database_=\"neo4j\",\n",
    "        )\n",
    "        \n",
    "        content = \"\"\n",
    "        #header = list(schema[node_type]['properties'].keys())\n",
    "        #content = \"\\t\".join(header) + \"\\n\"\n",
    "        for record in records:\n",
    "            \n",
    "            content += json.dumps(record.data()[variable_name]) + \"\\n\"\n",
    "\n",
    "        with open(os.path.join(output_directory, f\"{node_type}.json\"), 'w') as f:\n",
    "            f.write(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"neo4j-bigquery-project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://tsv/Morphology.tsv [Content-Type=text/tab-separated-values]...\n",
      "Copying file://tsv/Trial.tsv [Content-Type=text/tab-separated-values]...        \n",
      "Copying file://tsv/Institution.tsv [Content-Type=text/tab-separated-values]...  \n",
      "Copying file://tsv/Site.tsv [Content-Type=text/tab-separated-values]...         \n",
      "- [4 files][ 84.3 KiB/ 84.3 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://tsv/Condition.tsv [Content-Type=text/tab-separated-values]...\n",
      "Copying file://tsv/Category.tsv [Content-Type=text/tab-separated-values]...     \n",
      "- [6 files][109.6 KiB/109.6 KiB]                                                \n",
      "Operation completed over 6 objects/109.6 KiB.                                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.system(f'{PARAM[\"gsutil_path\"]}/gsutil cp -r tsv gs://{bucket_name}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://json/Condition.json [Content-Type=application/json]...\n",
      "Copying file://json/Site.json [Content-Type=application/json]...                \n",
      "Copying file://json/Institution.json [Content-Type=application/json]...         \n",
      "Copying file://json/Category.json [Content-Type=application/json]...            \n",
      "- [4 files][ 54.4 KiB/ 54.4 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://json/Trial.json [Content-Type=application/json]...\n",
      "Copying file://json/Morphology.json [Content-Type=application/json]...          \n",
      "\\ [6 files][133.4 KiB/133.4 KiB]                                                \n",
      "Operation completed over 6 objects/133.4 KiB.                                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'{PARAM[\"gsutil_path\"]}/gsutil cp -r json gs://{bucket_name}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(DatasetReference('vertex-ai-399007', 'neo4j'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_client = bigquery.Client()\n",
    "bigquery_project = \"vertex-ai-399007\"\n",
    "bigquery_dataset = \"neo4j\"\n",
    "bq_client.create_dataset(dataset=bigquery_dataset, exists_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_client = storage.Client()\n",
    "bucket = bucket_client.bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://neo4j-bigquery-project/tsv/Category.tsv Category\n",
      "gs://neo4j-bigquery-project/tsv/Condition.tsv Condition\n",
      "gs://neo4j-bigquery-project/tsv/Institution.tsv Institution\n",
      "gs://neo4j-bigquery-project/tsv/Morphology.tsv Morphology\n",
      "gs://neo4j-bigquery-project/tsv/Site.tsv Site\n",
      "gs://neo4j-bigquery-project/tsv/Trial.tsv Trial\n"
     ]
    }
   ],
   "source": [
    "# for f in bucket.list_blobs(prefix='tsv'):\n",
    "    \n",
    "#     full_path = f\"gs://{bucket_name}/{f.name}\"\n",
    "\n",
    "#     filename = f.name.split(\"/\")[1]\n",
    "#     nodename = filename.split(\".\")[0]\n",
    "#     print (full_path, nodename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://neo4j-bigquery-project/json/Category.json Category\n",
      "Loaded 300 rows.\n",
      "gs://neo4j-bigquery-project/json/Condition.json Condition\n",
      "Loaded 23 rows.\n",
      "gs://neo4j-bigquery-project/json/Institution.json Institution\n",
      "Loaded 25 rows.\n",
      "gs://neo4j-bigquery-project/json/Morphology.json Morphology\n",
      "Loaded 7 rows.\n",
      "gs://neo4j-bigquery-project/json/Site.json Site\n",
      "Loaded 128 rows.\n",
      "gs://neo4j-bigquery-project/json/Trial.json Trial\n",
      "Loaded 24 rows.\n"
     ]
    }
   ],
   "source": [
    "for f in bucket.list_blobs(prefix='json'):\n",
    "#for f in bucket.list_blobs(prefix='tsv'):\n",
    "    \n",
    "    full_path = f\"gs://{bucket_name}/{f.name}\"\n",
    "\n",
    "    filename = f.name.split(\"/\")[1]\n",
    "    nodename = filename.split(\".\")[0]\n",
    "    print (full_path, nodename)\n",
    "\n",
    "    #schema_setting = [bigquery.SchemaField(property_, schema_dict[nodename][property_]) for property_ in schema_dict[nodename].keys()]\n",
    "    schema_setting = []\n",
    "\n",
    "    # for property_ in schema_dict[nodename].keys():\n",
    "    #     type_ = schema_dict[nodename][property_]\n",
    "    #     if type_ != \"LIST\":\n",
    "    #         schema_setting.append(bigquery.SchemaField(property_, type_))\n",
    "    #     else:\n",
    " \n",
    "    #         schema_setting.append(bigquery.SchemaField(property_, \"STRING\", mode=\"REPEATED\"))\n",
    "\n",
    "    #print (schema_setting)\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "    #schema=schema_setting,\n",
    "    autodetect=True,\n",
    "    #skip_leading_rows=1,\n",
    "    #field_delimiter=\"\\t\",\n",
    "    # The source format defaults to CSV, so the line below is optional.\n",
    "    source_format=bigquery.SourceFormat.NEWLINE_DELIMITED_JSON,\n",
    "    )\n",
    "\n",
    "    table_id = f\"{bigquery_project}.{bigquery_dataset}.{nodename}\"\n",
    "\n",
    "    load_job = bq_client.load_table_from_uri(\n",
    "        full_path, table_id, job_config=job_config\n",
    "    )  # Make an API request.\n",
    "\n",
    "    load_job.result()  # Waits for the job to complete.\n",
    "\n",
    "    destination_table = bq_client.get_table(table_id)  # Make an API request.\n",
    "    print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo4j_bigquery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
